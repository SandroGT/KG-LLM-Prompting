{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca884981-dec5-4dc8-a2fa-da2cef3ac723",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "627fd98c-414a-4e46-810e-79763e423bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "! python -m nltk.downloader punkt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b796ff79-304f-4d05-b6ab-6cdaa1a32d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import tiktoken\n",
    "\n",
    "encoder = tiktoken.get_encoding('cl100k_base')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47863822-c3db-4777-af97-41d23184d1e6",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "# Load dataset data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a257db6-8c21-431f-b197-57218b20349f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rebel_20_data_path = Path('REBEL_20.json')\n",
    "with rebel_20_data_path.open('r') as f:\n",
    "    rebel_20_data = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "569757ef-d0ed-432e-b08d-ac7f68e3f346",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "# Get metrics data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20a64512-8854-46e2-af72-2f0eb1cfea28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics_dict(data):\n",
    "    metrics_data = dict()\n",
    "    for doc_id, doc_data in enumerate(data):        \n",
    "        doc_metrics = dict()\n",
    "\n",
    "        # --- Text centered stats\n",
    "        doc_metrics['text'] = {\n",
    "            'sentence count': len(sent_tokenize(doc_data['doc']['text'])),\n",
    "            'token count': len(encoder.encode(doc_data['doc']['text']))\n",
    "        }\n",
    "\n",
    "        # --- Entity centered metrics\n",
    "        gpt_entities = doc_data['entities']['gpt']\n",
    "        rebel_entities = list(set([e['surfaceform'] for e in doc_data['entities']['gold']]))\n",
    "        gpt_correct_entities = [e for e in gpt_entities if e['annotation']['entity correctness']]\n",
    "        gpt_missed_entities = doc_data['entities']['annotation']['gpt missed']\n",
    "        gpt_entity_description_from_text = [\n",
    "            e for e in gpt_entities\n",
    "            if e['annotation']['entity correctness'] and e['annotation']['description from text']\n",
    "        ]\n",
    "        gpt_rebel_entities_matches = [e for e in gpt_entities if e['annotation']['rebel match']]\n",
    "        doc_metrics['entities'] = {\n",
    "            'total':         len(gpt_entities),\n",
    "            'rebel count':   len(rebel_entities),\n",
    "            'correct':       len(gpt_correct_entities),\n",
    "            'missing':       len(gpt_missed_entities),\n",
    "            'from text':     len(gpt_entity_description_from_text),\n",
    "            'rebel matches': len(gpt_rebel_entities_matches)\n",
    "        }\n",
    "    \n",
    "        # --- Type centered metrics\n",
    "        gpt_types_all = [t for e in gpt_entities for t in e['types']]\n",
    "        gpt_types_first = [e['types'][0] for e in gpt_entities]\n",
    "        gpt_correct_types_all = [t for e in gpt_entities for t, b in zip(e['types'], e['annotation']['type correctness']) if b]\n",
    "        gpt_correct_types_first = [e['types'][0] for e in gpt_entities if e['annotation']['type correctness'][0]]\n",
    "        doc_metrics['types'] = {\n",
    "            'all total':   len(gpt_types_all),\n",
    "            'first total':   len(gpt_types_first),\n",
    "            'all correct': len(gpt_correct_types_all),\n",
    "            'first correct': len(gpt_correct_types_first),\n",
    "        }\n",
    "    \n",
    "        # --- Triplet centered metrics\n",
    "        gpt_triples = doc_data['triples']['gpt']\n",
    "        rebel_triples = list(set([\n",
    "            '|'.join([t[role]['surfaceform'].strip() for role in ['subject', 'predicate', 'object']])\n",
    "            for t in doc_data['triples']['gold']\n",
    "        ]))\n",
    "        gpt_correct_triples = [t for t in gpt_triples if t['annotation']['triple correctness']]\n",
    "        gpt_relation_from_text = [\n",
    "            t for t in gpt_triples\n",
    "            if t['annotation']['triple correctness'] and t['annotation']['relation from text']\n",
    "        ]\n",
    "        gpt_rebel_triples_matches = [t for t in gpt_triples if t['annotation']['rebel match']]\n",
    "        doc_metrics['triples'] = {\n",
    "            'total':         len(gpt_triples),\n",
    "            'rebel count':   len(rebel_triples),\n",
    "            'correct':       len(gpt_correct_triples),\n",
    "            'from text':     len(gpt_relation_from_text),\n",
    "            'rebel matches': len(gpt_rebel_triples_matches),\n",
    "        }\n",
    "\n",
    "        # --- Track metrics\n",
    "        metrics_data[doc_id] = doc_metrics\n",
    "    \n",
    "    return metrics_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "439f1a26-6db1-4f6a-b716-56da316f05b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = get_metrics_dict(rebel_20_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f9c1f2f-2ae4-4e1a-9946-afdb77ffe8b5",
   "metadata": {},
   "source": [
    "## Counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7361dbb6-3ff0-4332-b786-1d940cd36bcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents: 20\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of documents: {len(rebel_20_data):,d}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ae07035-97ae-46ec-97a1-d36819c7f52a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entities: 379\n"
     ]
    }
   ],
   "source": [
    "ce = sum([doc['entities']['total'] for _, doc in m.items()])\n",
    "print(f'Number of entities: {ce:,d}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "79df9ba3-8196-4b57-b30c-75b1f267b566",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of triples: 329\n"
     ]
    }
   ],
   "source": [
    "ct = sum([doc['triples']['total'] for _, doc in m.items()])\n",
    "print(f'Number of triples: {ct:,d}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e59b205-44c1-4514-b151-9368b30e27cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence count: 374\n"
     ]
    }
   ],
   "source": [
    "sentence_count = sum([doc['text']['sentence count'] for _, doc in m.items()])\n",
    "print(f'Sentence count: {sentence_count:,d}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6893f4cf-0621-499d-9b64-25f9d3e06b64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average token count: 602\n"
     ]
    }
   ],
   "source": [
    "token_count_list = [doc['text']['token count'] for _, doc in m.items()]\n",
    "print(f'Average token count: {round(sum(token_count_list)/len(token_count_list)):,d}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6aeda45-8641-4f6e-bc76-07748b073bd9",
   "metadata": {},
   "source": [
    "## Compute metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1554acae-11ea-41b2-91d7-28181a3bae25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Micro precision entities:  0.976\n"
     ]
    }
   ],
   "source": [
    "pe = sum([doc['entities']['correct'] for _, doc in m.items()]) / sum([doc['entities']['total'] for _, doc in m.items()])\n",
    "print(f'Micro precision entities: {pe: 4.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3127ca6b-cc4f-47ff-a339-b69c00e42395",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Micro recall entities:  0.896\n"
     ]
    }
   ],
   "source": [
    "re = sum([doc['entities']['correct'] for _, doc in m.items()]) / sum([doc['entities']['correct'] + doc['entities']['missing'] for _, doc in m.items()])\n",
    "print(f'Micro recall entities: {re: 4.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3821b9b4-9a4c-43a1-98a8-a016e7d7850b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Micro F1 entities:  0.934\n"
     ]
    }
   ],
   "source": [
    "f1e = 2 / (1 / pe + 1 / re)\n",
    "print(f'Micro F1 entities: {f1e: 4.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9e1e9068-ad59-4b92-94f5-645889adaf58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Micro precision types (all):  0.777\n"
     ]
    }
   ],
   "source": [
    "pta = sum([doc['types']['all correct'] for _, doc in m.items()]) / sum([doc['types']['all total'] for _, doc in m.items()])\n",
    "print(f'Micro precision types (all): {pta: 4.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "64b0789a-4a30-407c-9544-96c3e25cd559",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Micro precision types (only first):  0.939\n"
     ]
    }
   ],
   "source": [
    "ptf = sum([doc['types']['first correct'] for _, doc in m.items()]) / sum([doc['types']['first total'] for _, doc in m.items()])\n",
    "print(f'Micro precision types (only first): {ptf: 4.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eacb1116-dd5f-4e2c-9bcb-dad980d9606e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Micro precision triples:  0.836\n"
     ]
    }
   ],
   "source": [
    "pr = sum([doc['triples']['correct'] for _, doc in m.items()]) / sum([doc['triples']['total'] for _, doc in m.items()])\n",
    "print(f'Micro precision triples: {pr: 4.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "51c3e333-ed16-4d68-91ad-a73e8d2beeaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of entities descriptions from GPT knowledge:  0.322\n"
     ]
    }
   ],
   "source": [
    "ae = 1 - (sum([doc['entities']['from text'] for _, doc in m.items()]) / sum([doc['entities']['correct'] for _, doc in m.items()]))\n",
    "print(f'Percentage of entities descriptions from GPT knowledge: {ae: 4.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5e0d5a51-f2ce-4ec5-a713-446b918b4f63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of triples from GPT knowledge:  0.065\n"
     ]
    }
   ],
   "source": [
    "at = 1 - (sum([doc['triples']['from text'] for _, doc in m.items()]) / sum([doc['triples']['correct'] for _, doc in m.items()]))\n",
    "print(f'Percentage of triples from GPT knowledge: {at: 4.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5af4f02e-e446-4684-a54c-8ddba2e9081c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of new entities (vs REBEL):  0.451\n"
     ]
    }
   ],
   "source": [
    "ne = 1 - (sum([doc['entities']['rebel matches'] for _, doc in m.items()]) / sum([doc['entities']['total'] for _, doc in m.items()]))\n",
    "print(f'Percentage of new entities (vs REBEL): {ne: 4.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dc0059bf-7510-4e01-b216-cf651b855018",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of new triples (vs REBEL):  0.945\n"
     ]
    }
   ],
   "source": [
    "nt = 1 - (sum([doc['triples']['rebel matches'] for _, doc in m.items()]) / sum([doc['triples']['total'] for _, doc in m.items()]))\n",
    "print(f'Percentage of new triples (vs REBEL): {nt: 4.3f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
